{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training and Evaluating Our Rare Disease Prediction Models\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5749f4cf8d3041d9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:26:53,798 Starting training and evaluation notebook...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Config\n",
    "config = {\n",
    "    \"train_path\": \"../data/processed/train.jsonl\",\n",
    "    \"val_path\": \"../data/processed/val.jsonl\",\n",
    "    \"test_path\": \"../data/processed/test.jsonl\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_splits_cv\": 5,\n",
    "    \"rf_params\": {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 10,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "}\n",
    "\n",
    "np.random.seed(config['random_state'])\n",
    "torch.manual_seed(config['random_state'])\n",
    "\n",
    "# Logging\n",
    "if not os.path.exists('data/logs/'):\n",
    "    os.makedirs('data/logs/')\n",
    "logging.basicConfig(filename='data/logs/training_notebook.log', level=logging.INFO, format='%(asctime)s %(message)s')\n",
    "logger = logging.getLogger()\n",
    "logger.info(\"Starting training and evaluation notebook...\")\n",
    "\n",
    "assert os.path.exists(config[\"train_path\"]), f\"Train file not found: {config['train_path']}\"\n",
    "assert os.path.exists(config[\"val_path\"]), f\"Validation file not found: {config['val_path']}\"\n",
    "assert os.path.exists(config[\"test_path\"]), f\"Test file not found: {config['test_path']}\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:26:53.804245Z",
     "start_time": "2024-12-08T17:26:53.798409Z"
    }
   },
   "id": "1841509aac713424"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7169983399cc2844"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:27:19,732 Loaded data: Train=64, Val=16, Test=20\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_json(config[\"train_path\"], lines=True)\n",
    "val_df = pd.read_json(config[\"val_path\"], lines=True)\n",
    "test_df = pd.read_json(config[\"test_path\"], lines=True)\n",
    "\n",
    "required_cols = [\"positive_phenotypes\", \"all_candidate_genes\", \"true_diseases\"]\n",
    "for col in required_cols:\n",
    "    assert col in train_df.columns, f\"Missing required column: {col}\"\n",
    "    assert col in val_df.columns, f\"Missing required column: {col}\"\n",
    "    assert col in test_df.columns, f\"Missing required column: {col}\"\n",
    "\n",
    "combined_df = pd.concat([train_df, val_df], axis=0)\n",
    "logger.info(f\"Loaded data: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:27:19.739276Z",
     "start_time": "2024-12-08T17:27:19.722783Z"
    }
   },
   "id": "e62e187d386e7cec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction for Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "960d318b178ed954"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "all_phenos = set()\n",
    "all_genes = set()\n",
    "\n",
    "for ph_list in combined_df['positive_phenotypes']:\n",
    "    all_phenos.update(ph_list)\n",
    "for gene_list in combined_df['all_candidate_genes']:\n",
    "    all_genes.update(gene_list)\n",
    "\n",
    "pheno_classes = sorted(list(all_phenos))\n",
    "gene_classes = sorted(list(all_genes))\n",
    "\n",
    "pheno_mlb = MultiLabelBinarizer(classes=pheno_classes)\n",
    "gene_mlb = MultiLabelBinarizer(classes=gene_classes)\n",
    "\n",
    "pheno_matrix = pheno_mlb.fit_transform(combined_df['positive_phenotypes'])\n",
    "gene_matrix = gene_mlb.fit_transform(combined_df['all_candidate_genes'])\n",
    "\n",
    "X_combined = np.hstack([pheno_matrix, gene_matrix])\n",
    "y_combined = np.array([1 if d != 0 else 0 for d in combined_df['true_diseases']])\n",
    "\n",
    "pheno_matrix_test = pheno_mlb.transform(test_df['positive_phenotypes'])\n",
    "gene_matrix_test = gene_mlb.transform(test_df['all_candidate_genes'])\n",
    "X_test = np.hstack([pheno_matrix_test, gene_matrix_test])\n",
    "y_test = np.array([1 if d != 0 else 0 for d in test_df['true_diseases']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:27:54.568124Z",
     "start_time": "2024-12-08T17:27:54.561008Z"
    }
   },
   "id": "c3e26ae60746f965"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross-Validation with Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c64fe08e5707da50"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:28:56,102 Starting cross-validation...\n",
      "2024-12-08 18:28:56,175 Fold 1: F1-macro = 0.7922\n",
      "2024-12-08 18:28:56,239 Fold 2: F1-macro = 0.5429\n",
      "2024-12-08 18:28:56,302 Fold 3: F1-macro = 0.4667\n",
      "2024-12-08 18:28:56,369 Fold 4: F1-macro = 0.7257\n",
      "2024-12-08 18:28:56,432 Fold 5: F1-macro = 0.5636\n",
      "2024-12-08 18:28:56,434 Cross-validated F1-macro: 0.6182 ± 0.1212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated F1-macro: 0.6182 ± 0.1212\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(**config[\"rf_params\"])\n",
    "skf = StratifiedKFold(n_splits=config[\"n_splits_cv\"], shuffle=True, random_state=config[\"random_state\"])\n",
    "f1_scores = []\n",
    "logger.info(\"Starting cross-validation...\")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_combined, y_combined), start=1):\n",
    "    X_tr, X_val = X_combined[train_idx], X_combined[val_idx]\n",
    "    y_tr, y_val = y_combined[train_idx], y_combined[val_idx]\n",
    "    \n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    fold_f1 = f1_score(y_val, y_val_pred, average='macro', zero_division=0)\n",
    "    f1_scores.append(fold_f1)\n",
    "    logger.info(f\"Fold {fold_idx}: F1-macro = {fold_f1:.4f}\")\n",
    "\n",
    "mean_f1 = np.mean(f1_scores)\n",
    "std_f1 = np.std(f1_scores)\n",
    "logger.info(f\"Cross-validated F1-macro: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Cross-validated F1-macro: {mean_f1:.4f} ± {std_f1:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:28:56.441262Z",
     "start_time": "2024-12-08T17:28:56.104276Z"
    }
   },
   "id": "b5ebc51e4de565e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final Training on Combined Set and Testing\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d855510301a70a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:29:10,281 Retraining final model on combined train+val set.\n",
      "2024-12-08 18:29:10,349 Test results - Precision(macro): 0.4333, Recall(macro): 0.4405, F1(macro): 0.4357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.17      0.18         6\n",
      "           1       0.67      0.71      0.69        14\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.43      0.44      0.44        20\n",
      "weighted avg       0.53      0.55      0.54        20\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Retraining final model on combined train+val set.\")\n",
    "clf.fit(X_combined, y_combined)\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "test_recall = recall_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='macro', zero_division=0)\n",
    "\n",
    "logger.info(\n",
    "    f\"Test results - Precision(macro): {test_precision:.4f}, Recall(macro): {test_recall:.4f}, F1(macro): {test_f1:.4f}\"\n",
    ")\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:29:10.357411Z",
     "start_time": "2024-12-08T17:29:10.283658Z"
    }
   },
   "id": "7792a269ea164c4c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Importance\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5799c46f4a8c3591"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most important features:\n",
      "            feature  importance\n",
      "8        HP:0001257    0.074662\n",
      "32  ENSG00000144285    0.060936\n",
      "11       HP:0001332    0.060438\n",
      "35  ENSG00000177628    0.050995\n",
      "7        HP:0001251    0.048419\n",
      "21       HP:0012378    0.048321\n",
      "15       HP:0002367    0.043687\n",
      "13       HP:0002076    0.043364\n",
      "24  ENSG00000080815    0.042907\n",
      "36  ENSG00000186868    0.039434\n"
     ]
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "feature_names = pheno_classes + gene_classes\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "print(\"Top 10 most important features:\")\n",
    "print(importance_df.head(10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:29:29.398368Z",
     "start_time": "2024-12-08T17:29:29.387900Z"
    }
   },
   "id": "27b891081c9c302a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training a Simple MLP Model\n",
    "\n",
    "# This neural network model uses the same features and provides a comparative baseline.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f392eb6784e9473"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 18:30:06,364 Finished training MLP model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss=0.7140, Val Loss=0.7040, Val Prec=0.8000, Val Recall=0.3636, Val F1=0.5000\n",
      "Epoch 2/10: Train Loss=0.7025, Val Loss=0.6955, Val Prec=0.6667, Val Recall=0.3636, Val F1=0.4706\n",
      "Epoch 3/10: Train Loss=0.6932, Val Loss=0.6873, Val Prec=0.7778, Val Recall=0.6364, Val F1=0.7000\n",
      "Epoch 4/10: Train Loss=0.6833, Val Loss=0.6798, Val Prec=0.7273, Val Recall=0.7273, Val F1=0.7273\n",
      "Epoch 5/10: Train Loss=0.6747, Val Loss=0.6726, Val Prec=0.7692, Val Recall=0.9091, Val F1=0.8333\n",
      "Epoch 6/10: Train Loss=0.6656, Val Loss=0.6658, Val Prec=0.7143, Val Recall=0.9091, Val F1=0.8000\n",
      "Epoch 7/10: Train Loss=0.6580, Val Loss=0.6592, Val Prec=0.7333, Val Recall=1.0000, Val F1=0.8462\n",
      "Epoch 8/10: Train Loss=0.6506, Val Loss=0.6529, Val Prec=0.6875, Val Recall=1.0000, Val F1=0.8148\n",
      "Epoch 9/10: Train Loss=0.6418, Val Loss=0.6472, Val Prec=0.6875, Val Recall=1.0000, Val F1=0.8148\n",
      "Epoch 10/10: Train Loss=0.6352, Val Loss=0.6416, Val Prec=0.6875, Val Recall=1.0000, Val F1=0.8148\n"
     ]
    }
   ],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, dataframe, pheno_mlb, gene_mlb):\n",
    "        self.data = dataframe.copy()\n",
    "        self.pheno_mlb = pheno_mlb\n",
    "        self.gene_mlb = gene_mlb\n",
    "        self.data['pheno_vec'] = list(self.pheno_mlb.transform(self.data['positive_phenotypes']))\n",
    "        self.data['gene_vec'] = list(self.gene_mlb.transform(self.data['all_candidate_genes']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        pheno_vec = torch.tensor(row['pheno_vec'], dtype=torch.float32)\n",
    "        gene_vec = torch.tensor(row['gene_vec'], dtype=torch.float32)\n",
    "        x = torch.cat([pheno_vec, gene_vec])\n",
    "        y = torch.tensor([1.0 if row['true_diseases'] != 0 else 0.0], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sig(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "input_dim = len(pheno_classes) + len(gene_classes)\n",
    "train_data = PatientDataset(train_df, pheno_mlb, gene_mlb)\n",
    "val_data = PatientDataset(val_df, pheno_mlb, gene_mlb)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "model = SimpleMLP(input_dim=input_dim, hidden_dim=128)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for Xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(Xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    preds_list = []\n",
    "    true_list = []\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            pv = model(Xv)\n",
    "            vloss = criterion(pv, yv)\n",
    "            val_loss += vloss.item()\n",
    "            predicted = (pv >= 0.5).float().flatten().tolist()\n",
    "            truth = yv.flatten().tolist()\n",
    "            preds_list.extend(predicted)\n",
    "            true_list.extend(truth)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    precision = precision_score(true_list, preds_list, zero_division=0)\n",
    "    recall = recall_score(true_list, preds_list, zero_division=0)\n",
    "    f1 = f1_score(true_list, preds_list, zero_division=0)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, Val Prec={precision:.4f}, Val Recall={recall:.4f}, Val F1={f1:.4f}\")\n",
    "\n",
    "logger.info(\"Finished training MLP model.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T17:30:06.370968Z",
     "start_time": "2024-12-08T17:30:06.290956Z"
    }
   },
   "id": "37afb63c5ea02260"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4270812a9a561977"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
